{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgOFhCVVOvT/mG2E6kf720",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansbrunner/safety_data/blob/main/Clozapine/Convert_AE_PT_to_SOC_Clozapine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2VtOb6pRm6g"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "In this analysis, I aim to explore the use of data analysis techniques within the field of drug safety surveillance.\n",
        "First, I will create a file to convert reported Clozapine AE in PT to SOC using ChatGPT-3.5.\n",
        "This is not 100% accurate (manuel evaluation), but I get an acceptable result.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get Clozapine AE reports from FDA\n",
        "import time\n",
        "import json\n",
        "import requests\n",
        "base_url = 'https://api.fda.gov/drug/event.json'\n",
        "\n",
        "# Parameters for the API request\n",
        "limit = 1000  # Fetch 1000 reports at a time\n",
        "total_reports_to_fetch = 10000  # The total number of reports to get\n",
        "total_reports_fetched = 0  # Counter\n",
        "data = []  # Store all reports\n",
        "\n",
        "# Loop\n",
        "while total_reports_fetched < total_reports_to_fetch:\n",
        "    # Fetch the next batch of reports\n",
        "    url = f'{base_url}?search=clozapine&limit={limit}&skip={total_reports_fetched}'\n",
        "    response = requests.get(url)\n",
        "    _data = response.json()\n",
        "\n",
        "    # Add the fetched results to the all_data list\n",
        "    data.extend(_data['results'])\n",
        "\n",
        "    # Update the total number of reports fetched\n",
        "    total_reports_fetched += len(_data['results'])\n",
        "\n",
        "    # Sleep\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "id": "FKlBdulqR5ug"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all unique AE as PT\n",
        "# Empty set to store unique Preferred Terms (PT)\n",
        "unique_pts = set()\n",
        "\n",
        "# Loop through each report in the data\n",
        "for report in data:\n",
        "    reactions = report['patient'].get('reaction', [])\n",
        "    for reaction in reactions:\n",
        "        event = reaction['reactionmeddrapt'] # preferred term\n",
        "        unique_pts.add(event)\n",
        "\n",
        "# Convert the set to list\n",
        "unique_pts_list = list(unique_pts)"
      ],
      "metadata": {
        "id": "uvkGG8fbSDTN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use chatGPT to map PTs to SOCs\n",
        "# Takes some time and costs money (Not a lot though)\n",
        "import openai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Get openai api key\n",
        "with open('openai_key.txt', 'r') as file:\n",
        "    openai_api_key = file.read().strip()\n",
        "\n",
        "openai.api_key = openai_api_key\n",
        "# Ask GPT-3.5 to map PTs to SOCs\n",
        "def map_pt_to_soc(pt):\n",
        "    try:\n",
        "        # Call GPT-3.5\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"What is the medDra System Organ Class (SOC) for the following medDra Preferred Term (PT): '{pt}'? Only write the SOC.\"}\n",
        "            ],\n",
        "            max_tokens=50,\n",
        "            n=1,\n",
        "            temperature=0.0\n",
        "        )\n",
        "        # Get the SOC from the response\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        # Handle API call failure\n",
        "        print(f\"Error for PT '{pt}': {e}\")\n",
        "        return np.nan\n",
        "\n",
        "# Create a DataFrame\n",
        "pt_to_soc = pd.DataFrame({'PT': unique_pts_list}) # list from before\n",
        "\n",
        "# New column 'SOC' with nan values\n",
        "pt_to_soc['SOC'] = np.nan\n",
        "\n",
        "# Map PTs to SOCs using GPT-3.5\n",
        "pt_to_soc['SOC'] = pt_to_soc['PT'].apply(map_pt_to_soc)"
      ],
      "metadata": {
        "id": "DqVVlAFRSDwc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Responses are not in same format, clean!\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# MedDRA SOCs\n",
        "meddra_socs = [\n",
        "    \"Blood and lymphatic system disorders\",\n",
        "    \"Cardiac disorders\",\n",
        "    \"Congenital, familial and genetic disorders\",\n",
        "    \"Ear and labyrinth disorders\",\n",
        "    \"Endocrine disorders\",\n",
        "    \"Eye disorders\",\n",
        "    \"Gastrointestinal disorders\",\n",
        "    \"General disorders and administration site conditions\",\n",
        "    \"Hepatobiliary disorders\",\n",
        "    \"Immune system disorders\",\n",
        "    \"Infections and infestations\",\n",
        "    \"Injury, poisoning and procedural complications\",\n",
        "    \"Investigations\",\n",
        "    \"Metabolism and nutrition disorders\",\n",
        "    \"Musculoskeletal and connective tissue disorders\",\n",
        "    \"Neoplasms benign, malignant and unspecified (incl cysts and polyps)\",\n",
        "    \"Nervous system disorders\",\n",
        "    \"Pregnancy, puerperium and perinatal conditions\",\n",
        "    \"Product issues\",\n",
        "    \"Psychiatric disorders\",\n",
        "    \"Renal and urinary disorders\",\n",
        "    \"Reproductive system and breast disorders\",\n",
        "    \"Respiratory, thoracic and mediastinal disorders\",\n",
        "    \"Skin and subcutaneous tissue disorders\",\n",
        "    \"Social circumstances\",\n",
        "    \"Surgical and medical procedures\",\n",
        "    \"Vascular disorders\"\n",
        "]\n",
        "\n",
        "# Removing special characters and convert to lowercase\n",
        "def clean_string(s):\n",
        "    return re.sub(r'[^\\w\\s]', '', s).strip().lower()\n",
        "\n",
        "# Match SOCs by cleaning and comparing the strings\n",
        "def normalize_soc(soc_response):\n",
        "    cleaned_response = clean_string(soc_response)\n",
        "\n",
        "    # Compare the cleaned response with the cleaned MedDRA SOC list\n",
        "    for official_soc in meddra_socs:\n",
        "        cleaned_soc = clean_string(official_soc)\n",
        "        if cleaned_soc in cleaned_response:\n",
        "            return official_soc  # Return the official SOC if matched\n",
        "\n",
        "    return None  # Return None if match is not found\n",
        "\n",
        "df = pt_to_soc.copy()\n",
        "# Match SOCs\n",
        "df['SOC_normalized'] = df['SOC'].apply(normalize_soc)\n",
        "\n",
        "# Print a sample of 10 random old and corrected SOCs\n",
        "#sampled_df = df[['SOC', 'SOC_normalized']].sample(n=10, random_state=10)\n",
        "#pd.set_option('display.max_colwidth', None)  # Ensure long text isn't truncated\n",
        "\n",
        "\n",
        "# Save\n",
        "df.to_csv('pt_soc_mapping.csv')\n",
        "from google.colab import files\n",
        "# Download the file to your desktop\n",
        "files.download('pt_soc_mapping.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YjjLWBbtUgK4",
        "outputId": "86950895-8795-4b19-faeb-9897e58fd0cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ce685456-a4ff-418c-9758-2a809af8b022\", \"pt_soc_mapping.csv\", 354440)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}